# coding: utf-8

"""
    ICA Rest API

    This API can be used to interact with Illumina Connected Analytics.<br> <h2>Authentication</h2> <p> Authentication to the  API can be done in multiple ways:<br> <ul><li>For the entire API, except for the POST /tokens endpoint: API-key + JWT</li> <li>Only for the POST /tokens endpoint: API-key + Basic Authentication</li></ul> </p> <p> <h4>API-key</h4> API keys are managed within the Illumina portal where you can manage your profile after you have logged on. The API-key has to be provided in the X-API-Key header parameter when executing API calls to ICA. In the background, a JWT will be requested at the IDP of Illumina to create a session. A good practice is to not use the API-key for every API call, but to first generate a JWT and to use that for authentication in subsequent calls.<br> </p> <p> <h4>JWT</h4> To avoid using an API-key for each call, we recommend to request a JWT via the POST /tokens endpoint  using this API-key. The JWT will expire after a pre-configured period specified by a tenant administrator through the IAM console in the Illumina portal. The JWT is the preferred way for authentication.<br>A not yet expired, still valid JWT could be refreshed using the POST /tokens:refresh endpoint.<br>Refreshing the JWT is not possible if the JWT was generated by using an API-key.<br> </p> <p> <h4>Basic Authentication</h4> Basic authentication is only supported by the POST /tokens endpoint for generating a JWT. Use \"Basic base64encoded(emailaddress:password)\" in the \"Authorization\" header parameter for this authentication method. In case having access to multiple tenants using the same email-address, also provide the \"tenant\" request parameter to indicate what tenant you would like to request a JWT for. </p> <p> <h2>Compression</h2> If the API client provides request header 'Accept-Encoding' with value 'gzip', then the API applies GZIP compression on the JSON response. This significantly reduces the size and thus the download time of the response, which results in faster end-to-end API calls. In case of compression, the API also provides response header 'Content-Encoding' with value 'gzip', as indication for the client that decompression is required. </p> 

    The version of the OpenAPI document: 3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class LoadDataInBaseRequest(BaseModel):
    """
    LoadDataInBaseRequest
    """ # noqa: E501
    allow_quoted_newlines: Optional[StrictBool] = Field(default=False, description="Enable to include newlines contained in quoted data sections in the cell's value. When disabled, newlines will signal a new row", alias="allowQuotedNewlines")
    data_id: StrictStr = Field(description="ID of the data to load into the table", alias="dataId")
    delimiter: Optional[StrictStr] = Field(default=',', description="field delimiter")
    encoding: Optional[StrictStr] = Field(default='UTF8', description="Encoding")
    force_load: Optional[StrictBool] = Field(default=False, description="When false (default): the data will not be loaded if it was already previously loaded to table ; when true, the data will be loaded even if already loaded in the past", alias="forceLoad")
    header_rows_to_skip: Optional[StrictInt] = Field(default=1, description="number of rows to skip (usually for headers)", alias="headerRowsToSkip")
    ignore_unknown_values: Optional[StrictBool] = Field(default=False, description="When enabled, rows with extra column values that do not match the schema will be ignored and will not be loaded into the table, rows with too few values will receive default value null", alias="ignoreUnknownValues")
    include_references: Optional[StrictBool] = Field(default=True, description="Include references", alias="includeReferences")
    include_data_reference: Optional[StrictBool] = Field(default=True, description="Include Data Reference", alias="includeDataReference")
    include_sample_reference: Optional[StrictBool] = Field(default=True, description="Include Sample Reference", alias="includeSampleReference")
    include_pipeline_reference: Optional[StrictBool] = Field(default=True, description="Include Pipeline Reference", alias="includePipelineReference")
    include_pipeline_execution_reference: Optional[StrictBool] = Field(default=True, description="Include Pipeline Execution Reference", alias="includePipelineExecutionReference")
    include_tenant_reference: Optional[StrictBool] = Field(default=True, description="Include Tenant Reference", alias="includeTenantReference")
    null_marker: Optional[StrictStr] = Field(default=None, description="Specifies a string that represents a null value in a CSV/TSV file.", alias="nullMarker")
    number_of_errors_allowed: Optional[StrictInt] = Field(default=0, description="The maximum number of bad records that Base can ignore when running the job", alias="numberOfErrorsAllowed")
    quote: Optional[StrictStr] = Field(default=None, description="The value that is used to quote data sections in a CSV/TSV file")
    write_preference: Optional[StrictStr] = Field(default='APPENDTOTABLE', description="specifies how to write data in the table.", alias="writePreference")
    __properties: ClassVar[List[str]] = ["allowQuotedNewlines", "dataId", "delimiter", "encoding", "forceLoad", "headerRowsToSkip", "ignoreUnknownValues", "includeReferences", "includeDataReference", "includeSampleReference", "includePipelineReference", "includePipelineExecutionReference", "includeTenantReference", "nullMarker", "numberOfErrorsAllowed", "quote", "writePreference"]

    @field_validator('encoding')
    def encoding_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['UTF8', 'ISO88591']):
            raise ValueError("must be one of enum values ('UTF8', 'ISO88591')")
        return value

    @field_validator('write_preference')
    def write_preference_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['WRITEIFEMPTY', 'APPENDTOTABLE', 'OVERWRITETABLE']):
            raise ValueError("must be one of enum values ('WRITEIFEMPTY', 'APPENDTOTABLE', 'OVERWRITETABLE')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of LoadDataInBaseRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # set to None if allow_quoted_newlines (nullable) is None
        # and model_fields_set contains the field
        if self.allow_quoted_newlines is None and "allow_quoted_newlines" in self.model_fields_set:
            _dict['allowQuotedNewlines'] = None

        # set to None if delimiter (nullable) is None
        # and model_fields_set contains the field
        if self.delimiter is None and "delimiter" in self.model_fields_set:
            _dict['delimiter'] = None

        # set to None if encoding (nullable) is None
        # and model_fields_set contains the field
        if self.encoding is None and "encoding" in self.model_fields_set:
            _dict['encoding'] = None

        # set to None if force_load (nullable) is None
        # and model_fields_set contains the field
        if self.force_load is None and "force_load" in self.model_fields_set:
            _dict['forceLoad'] = None

        # set to None if header_rows_to_skip (nullable) is None
        # and model_fields_set contains the field
        if self.header_rows_to_skip is None and "header_rows_to_skip" in self.model_fields_set:
            _dict['headerRowsToSkip'] = None

        # set to None if include_references (nullable) is None
        # and model_fields_set contains the field
        if self.include_references is None and "include_references" in self.model_fields_set:
            _dict['includeReferences'] = None

        # set to None if include_data_reference (nullable) is None
        # and model_fields_set contains the field
        if self.include_data_reference is None and "include_data_reference" in self.model_fields_set:
            _dict['includeDataReference'] = None

        # set to None if include_sample_reference (nullable) is None
        # and model_fields_set contains the field
        if self.include_sample_reference is None and "include_sample_reference" in self.model_fields_set:
            _dict['includeSampleReference'] = None

        # set to None if include_pipeline_reference (nullable) is None
        # and model_fields_set contains the field
        if self.include_pipeline_reference is None and "include_pipeline_reference" in self.model_fields_set:
            _dict['includePipelineReference'] = None

        # set to None if include_pipeline_execution_reference (nullable) is None
        # and model_fields_set contains the field
        if self.include_pipeline_execution_reference is None and "include_pipeline_execution_reference" in self.model_fields_set:
            _dict['includePipelineExecutionReference'] = None

        # set to None if include_tenant_reference (nullable) is None
        # and model_fields_set contains the field
        if self.include_tenant_reference is None and "include_tenant_reference" in self.model_fields_set:
            _dict['includeTenantReference'] = None

        # set to None if null_marker (nullable) is None
        # and model_fields_set contains the field
        if self.null_marker is None and "null_marker" in self.model_fields_set:
            _dict['nullMarker'] = None

        # set to None if number_of_errors_allowed (nullable) is None
        # and model_fields_set contains the field
        if self.number_of_errors_allowed is None and "number_of_errors_allowed" in self.model_fields_set:
            _dict['numberOfErrorsAllowed'] = None

        # set to None if quote (nullable) is None
        # and model_fields_set contains the field
        if self.quote is None and "quote" in self.model_fields_set:
            _dict['quote'] = None

        # set to None if write_preference (nullable) is None
        # and model_fields_set contains the field
        if self.write_preference is None and "write_preference" in self.model_fields_set:
            _dict['writePreference'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of LoadDataInBaseRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "allowQuotedNewlines": obj.get("allowQuotedNewlines") if obj.get("allowQuotedNewlines") is not None else False,
            "dataId": obj.get("dataId"),
            "delimiter": obj.get("delimiter") if obj.get("delimiter") is not None else ',',
            "encoding": obj.get("encoding") if obj.get("encoding") is not None else 'UTF8',
            "forceLoad": obj.get("forceLoad") if obj.get("forceLoad") is not None else False,
            "headerRowsToSkip": obj.get("headerRowsToSkip") if obj.get("headerRowsToSkip") is not None else 1,
            "ignoreUnknownValues": obj.get("ignoreUnknownValues") if obj.get("ignoreUnknownValues") is not None else False,
            "includeReferences": obj.get("includeReferences") if obj.get("includeReferences") is not None else True,
            "includeDataReference": obj.get("includeDataReference") if obj.get("includeDataReference") is not None else True,
            "includeSampleReference": obj.get("includeSampleReference") if obj.get("includeSampleReference") is not None else True,
            "includePipelineReference": obj.get("includePipelineReference") if obj.get("includePipelineReference") is not None else True,
            "includePipelineExecutionReference": obj.get("includePipelineExecutionReference") if obj.get("includePipelineExecutionReference") is not None else True,
            "includeTenantReference": obj.get("includeTenantReference") if obj.get("includeTenantReference") is not None else True,
            "nullMarker": obj.get("nullMarker"),
            "numberOfErrorsAllowed": obj.get("numberOfErrorsAllowed") if obj.get("numberOfErrorsAllowed") is not None else 0,
            "quote": obj.get("quote"),
            "writePreference": obj.get("writePreference") if obj.get("writePreference") is not None else 'APPENDTOTABLE'
        })
        return _obj


