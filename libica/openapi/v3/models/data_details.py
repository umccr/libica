# coding: utf-8

"""
    ICA Rest API

    This API can be used to interact with Illumina Connected Analytics.<br> <h2>Authentication</h2> <p> Authentication to the  API can be done in multiple ways:<br> <ul><li>For the entire API, except for the POST /tokens endpoint: API-key + JWT</li> <li>Only for the POST /tokens endpoint: API-key + Basic Authentication</li></ul> </p> <p> <h4>API-key</h4> API keys are managed within the Illumina portal where you can manage your profile after you have logged on. The API-key has to be provided in the X-API-Key header parameter when executing API calls to ICA. In the background, a JWT will be requested at the IDP of Illumina to create a session. A good practice is to not use the API-key for every API call, but to first generate a JWT and to use that for authentication in subsequent calls.<br> </p> <p> <h4>JWT</h4> To avoid using an API-key for each call, we recommend to request a JWT via the POST /tokens endpoint  using this API-key. The JWT will expire after a pre-configured period specified by a tenant administrator through the IAM console in the Illumina portal. The JWT is the preferred way for authentication.<br>A not yet expired, still valid JWT could be refreshed using the POST /tokens:refresh endpoint.<br>Refreshing the JWT is not possible if the JWT was generated by using an API-key.<br> </p> <p> <h4>Basic Authentication</h4> Basic authentication is only supported by the POST /tokens endpoint for generating a JWT. Use \"Basic base64encoded(emailaddress:password)\" in the \"Authorization\" header parameter for this authentication method. In case having access to multiple tenants using the same email-address, also provide the \"tenant\" request parameter to indicate what tenant you would like to request a JWT for. </p> <p> <h2>Compression</h2> If the API client provides request header 'Accept-Encoding' with value 'gzip', then the API applies GZIP compression on the JSON response. This significantly reduces the size and thus the download time of the response, which results in faster end-to-end API calls. In case of compression, the API also provides response header 'Content-Encoding' with value 'gzip', as indication for the client that decompression is required. </p> 

    The version of the OpenAPI document: 3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from libica.openapi.v3.models.application_v4 import ApplicationV4
from libica.openapi.v3.models.data_format import DataFormat
from libica.openapi.v3.models.data_tag import DataTag
from libica.openapi.v3.models.region import Region
from libica.openapi.v3.models.sequencing_run import SequencingRun
from typing import Optional, Set
from typing_extensions import Self

class DataDetails(BaseModel):
    """
    DataDetails
    """ # noqa: E501
    time_created: datetime = Field(alias="timeCreated")
    time_modified: datetime = Field(alias="timeModified")
    creator_id: Optional[StrictStr] = Field(default=None, alias="creatorId")
    tenant_id: StrictStr = Field(alias="tenantId")
    tenant_name: Optional[StrictStr] = Field(default=None, alias="tenantName")
    owning_project_id: StrictStr = Field(alias="owningProjectId")
    owning_project_name: Optional[StrictStr] = Field(default=None, alias="owningProjectName")
    name: StrictStr = Field(description="The name of the file/folder as it was uploaded.")
    path: Optional[StrictStr] = Field(default=None, description="The user friendly path of the parent of this data.")
    file_size_in_bytes: Optional[StrictInt] = Field(default=None, description="The size of the file in bytes. Folders do not have a size.", alias="fileSizeInBytes")
    status: StrictStr
    tags: DataTag
    format: Optional[DataFormat] = None
    data_type: StrictStr = Field(alias="dataType")
    object_e_tag: Optional[StrictStr] = Field(default=None, description="The file's ETag, as received from the cloud provider. Not to be confused with the ETag reponse header of this API.", alias="objectETag")
    stored_for_the_first_time_at: Optional[datetime] = Field(default=None, description="Specifies when the data object was stored for the first time", alias="storedForTheFirstTimeAt")
    region: Optional[Region] = None
    application: Optional[ApplicationV4] = None
    will_be_archived_at: Optional[datetime] = Field(default=None, description="Specifies when the data object will be archived.", alias="willBeArchivedAt")
    will_be_deleted_at: Optional[datetime] = Field(default=None, description="Specifies when the data object will be deleted.", alias="willBeDeletedAt")
    sequencing_run: Optional[SequencingRun] = Field(default=None, alias="sequencingRun")
    __properties: ClassVar[List[str]] = ["timeCreated", "timeModified", "creatorId", "tenantId", "tenantName", "owningProjectId", "owningProjectName", "name", "path", "fileSizeInBytes", "status", "tags", "format", "dataType", "objectETag", "storedForTheFirstTimeAt", "region", "application", "willBeArchivedAt", "willBeDeletedAt", "sequencingRun"]

    @field_validator('status')
    def status_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(['PARTIAL', 'AVAILABLE', 'ARCHIVING', 'ARCHIVED', 'UNARCHIVING', 'DELETING']):
            raise ValueError("must be one of enum values ('PARTIAL', 'AVAILABLE', 'ARCHIVING', 'ARCHIVED', 'UNARCHIVING', 'DELETING')")
        return value

    @field_validator('data_type')
    def data_type_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(['FILE', 'FOLDER']):
            raise ValueError("must be one of enum values ('FILE', 'FOLDER')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DataDetails from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of tags
        if self.tags:
            _dict['tags'] = self.tags.to_dict()
        # override the default output from pydantic by calling `to_dict()` of format
        if self.format:
            _dict['format'] = self.format.to_dict()
        # override the default output from pydantic by calling `to_dict()` of region
        if self.region:
            _dict['region'] = self.region.to_dict()
        # override the default output from pydantic by calling `to_dict()` of application
        if self.application:
            _dict['application'] = self.application.to_dict()
        # override the default output from pydantic by calling `to_dict()` of sequencing_run
        if self.sequencing_run:
            _dict['sequencingRun'] = self.sequencing_run.to_dict()
        # set to None if creator_id (nullable) is None
        # and model_fields_set contains the field
        if self.creator_id is None and "creator_id" in self.model_fields_set:
            _dict['creatorId'] = None

        # set to None if tenant_name (nullable) is None
        # and model_fields_set contains the field
        if self.tenant_name is None and "tenant_name" in self.model_fields_set:
            _dict['tenantName'] = None

        # set to None if owning_project_name (nullable) is None
        # and model_fields_set contains the field
        if self.owning_project_name is None and "owning_project_name" in self.model_fields_set:
            _dict['owningProjectName'] = None

        # set to None if path (nullable) is None
        # and model_fields_set contains the field
        if self.path is None and "path" in self.model_fields_set:
            _dict['path'] = None

        # set to None if file_size_in_bytes (nullable) is None
        # and model_fields_set contains the field
        if self.file_size_in_bytes is None and "file_size_in_bytes" in self.model_fields_set:
            _dict['fileSizeInBytes'] = None

        # set to None if format (nullable) is None
        # and model_fields_set contains the field
        if self.format is None and "format" in self.model_fields_set:
            _dict['format'] = None

        # set to None if object_e_tag (nullable) is None
        # and model_fields_set contains the field
        if self.object_e_tag is None and "object_e_tag" in self.model_fields_set:
            _dict['objectETag'] = None

        # set to None if stored_for_the_first_time_at (nullable) is None
        # and model_fields_set contains the field
        if self.stored_for_the_first_time_at is None and "stored_for_the_first_time_at" in self.model_fields_set:
            _dict['storedForTheFirstTimeAt'] = None

        # set to None if application (nullable) is None
        # and model_fields_set contains the field
        if self.application is None and "application" in self.model_fields_set:
            _dict['application'] = None

        # set to None if will_be_archived_at (nullable) is None
        # and model_fields_set contains the field
        if self.will_be_archived_at is None and "will_be_archived_at" in self.model_fields_set:
            _dict['willBeArchivedAt'] = None

        # set to None if will_be_deleted_at (nullable) is None
        # and model_fields_set contains the field
        if self.will_be_deleted_at is None and "will_be_deleted_at" in self.model_fields_set:
            _dict['willBeDeletedAt'] = None

        # set to None if sequencing_run (nullable) is None
        # and model_fields_set contains the field
        if self.sequencing_run is None and "sequencing_run" in self.model_fields_set:
            _dict['sequencingRun'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DataDetails from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "timeCreated": obj.get("timeCreated"),
            "timeModified": obj.get("timeModified"),
            "creatorId": obj.get("creatorId"),
            "tenantId": obj.get("tenantId"),
            "tenantName": obj.get("tenantName"),
            "owningProjectId": obj.get("owningProjectId"),
            "owningProjectName": obj.get("owningProjectName"),
            "name": obj.get("name"),
            "path": obj.get("path"),
            "fileSizeInBytes": obj.get("fileSizeInBytes"),
            "status": obj.get("status"),
            "tags": DataTag.from_dict(obj["tags"]) if obj.get("tags") is not None else None,
            "format": DataFormat.from_dict(obj["format"]) if obj.get("format") is not None else None,
            "dataType": obj.get("dataType"),
            "objectETag": obj.get("objectETag"),
            "storedForTheFirstTimeAt": obj.get("storedForTheFirstTimeAt"),
            "region": Region.from_dict(obj["region"]) if obj.get("region") is not None else None,
            "application": ApplicationV4.from_dict(obj["application"]) if obj.get("application") is not None else None,
            "willBeArchivedAt": obj.get("willBeArchivedAt"),
            "willBeDeletedAt": obj.get("willBeDeletedAt"),
            "sequencingRun": SequencingRun.from_dict(obj["sequencingRun"]) if obj.get("sequencingRun") is not None else None
        })
        return _obj


