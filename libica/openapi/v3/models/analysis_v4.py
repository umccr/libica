# coding: utf-8

"""
    ICA Rest API

    This API can be used to interact with Illumina Connected Analytics.<br> <h2>Authentication</h2> <p> Authentication to the  API can be done in multiple ways:<br> <ul><li>For the entire API, except for the POST /tokens endpoint: API-key + JWT</li> <li>Only for the POST /tokens endpoint: API-key + Basic Authentication</li></ul> </p> <p> <h4>API-key</h4> API keys are managed within the Illumina portal where you can manage your profile after you have logged on. The API-key has to be provided in the X-API-Key header parameter when executing API calls to ICA. In the background, a JWT will be requested at the IDP of Illumina to create a session. A good practice is to not use the API-key for every API call, but to first generate a JWT and to use that for authentication in subsequent calls.<br> </p> <p> <h4>JWT</h4> To avoid using an API-key for each call, we recommend to request a JWT via the POST /tokens endpoint  using this API-key. The JWT will expire after a pre-configured period specified by a tenant administrator through the IAM console in the Illumina portal. The JWT is the preferred way for authentication.<br>A not yet expired, still valid JWT could be refreshed using the POST /tokens:refresh endpoint.<br>Refreshing the JWT is not possible if the JWT was generated by using an API-key.<br> </p> <p> <h4>Basic Authentication</h4> Basic authentication is only supported by the POST /tokens endpoint for generating a JWT. Use \"Basic base64encoded(emailaddress:password)\" in the \"Authorization\" header parameter for this authentication method. In case having access to multiple tenants using the same email-address, also provide the \"tenant\" request parameter to indicate what tenant you would like to request a JWT for. </p> <p> <h2>Compression</h2> If the API client provides request header 'Accept-Encoding' with value 'gzip', then the API applies GZIP compression on the JSON response. This significantly reduces the size and thus the download time of the response, which results in faster end-to-end API calls. In case of compression, the API also provides response header 'Content-Encoding' with value 'gzip', as indication for the client that decompression is required. </p> 

    The version of the OpenAPI document: 3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from libica.openapi.v3.models.analysis_storage_v4 import AnalysisStorageV4
from libica.openapi.v3.models.analysis_tag import AnalysisTag
from libica.openapi.v3.models.application_v4 import ApplicationV4
from libica.openapi.v3.models.pipeline_v4 import PipelineV4
from libica.openapi.v3.models.tenant_identifier import TenantIdentifier
from libica.openapi.v3.models.user_identifier import UserIdentifier
from libica.openapi.v3.models.workflow_session_v4 import WorkflowSessionV4
from typing import Optional, Set
from typing_extensions import Self

class AnalysisV4(BaseModel):
    """
    AnalysisV4
    """ # noqa: E501
    id: StrictStr
    time_created: datetime = Field(alias="timeCreated")
    time_modified: datetime = Field(alias="timeModified")
    owner: UserIdentifier
    tenant: TenantIdentifier
    reference: Annotated[str, Field(min_length=1, strict=True, max_length=255)] = Field(description="The unique reference of the analysis")
    user_reference: Annotated[str, Field(min_length=1, strict=True, max_length=255)] = Field(description="The user reference of the analysis", alias="userReference")
    pipeline: PipelineV4
    workflow_session: Optional[WorkflowSessionV4] = Field(default=None, alias="workflowSession")
    status: Annotated[str, Field(strict=True)] = Field(description="The status of the analysis")
    start_date: Optional[datetime] = Field(default=None, description="When the analysis was started", alias="startDate")
    end_date: Optional[datetime] = Field(default=None, description="When the analysis was finished", alias="endDate")
    summary: Optional[StrictStr] = Field(default=None, description="The summary of the analysis")
    analysis_storage: Optional[AnalysisStorageV4] = Field(default=None, alias="analysisStorage")
    analysis_priority: Optional[Annotated[str, Field(strict=True)]] = Field(default=None, description="The priority of the analysis", alias="analysisPriority")
    tags: AnalysisTag
    application: Optional[ApplicationV4] = None
    __properties: ClassVar[List[str]] = ["id", "timeCreated", "timeModified", "owner", "tenant", "reference", "userReference", "pipeline", "workflowSession", "status", "startDate", "endDate", "summary", "analysisStorage", "analysisPriority", "tags", "application"]

    @field_validator('status')
    def status_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if not re.match(r"REQUESTED|QUEUED|INITIALIZING|PREPARING_INPUTS|IN_PROGRESS|GENERATING_OUTPUTS|AWAITING_INPUT|ABORTING|SUCCEEDED|FAILED|FAILED_FINAL|ABORTED", value):
            raise ValueError(r"must validate the regular expression /REQUESTED|QUEUED|INITIALIZING|PREPARING_INPUTS|IN_PROGRESS|GENERATING_OUTPUTS|AWAITING_INPUT|ABORTING|SUCCEEDED|FAILED|FAILED_FINAL|ABORTED/")
        return value

    @field_validator('analysis_priority')
    def analysis_priority_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r"LOW|MEDIUM|HIGH", value):
            raise ValueError(r"must validate the regular expression /LOW|MEDIUM|HIGH/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of AnalysisV4 from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of owner
        if self.owner:
            _dict['owner'] = self.owner.to_dict()
        # override the default output from pydantic by calling `to_dict()` of tenant
        if self.tenant:
            _dict['tenant'] = self.tenant.to_dict()
        # override the default output from pydantic by calling `to_dict()` of pipeline
        if self.pipeline:
            _dict['pipeline'] = self.pipeline.to_dict()
        # override the default output from pydantic by calling `to_dict()` of workflow_session
        if self.workflow_session:
            _dict['workflowSession'] = self.workflow_session.to_dict()
        # override the default output from pydantic by calling `to_dict()` of analysis_storage
        if self.analysis_storage:
            _dict['analysisStorage'] = self.analysis_storage.to_dict()
        # override the default output from pydantic by calling `to_dict()` of tags
        if self.tags:
            _dict['tags'] = self.tags.to_dict()
        # override the default output from pydantic by calling `to_dict()` of application
        if self.application:
            _dict['application'] = self.application.to_dict()
        # set to None if start_date (nullable) is None
        # and model_fields_set contains the field
        if self.start_date is None and "start_date" in self.model_fields_set:
            _dict['startDate'] = None

        # set to None if end_date (nullable) is None
        # and model_fields_set contains the field
        if self.end_date is None and "end_date" in self.model_fields_set:
            _dict['endDate'] = None

        # set to None if summary (nullable) is None
        # and model_fields_set contains the field
        if self.summary is None and "summary" in self.model_fields_set:
            _dict['summary'] = None

        # set to None if analysis_priority (nullable) is None
        # and model_fields_set contains the field
        if self.analysis_priority is None and "analysis_priority" in self.model_fields_set:
            _dict['analysisPriority'] = None

        # set to None if application (nullable) is None
        # and model_fields_set contains the field
        if self.application is None and "application" in self.model_fields_set:
            _dict['application'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of AnalysisV4 from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "id": obj.get("id"),
            "timeCreated": obj.get("timeCreated"),
            "timeModified": obj.get("timeModified"),
            "owner": UserIdentifier.from_dict(obj["owner"]) if obj.get("owner") is not None else None,
            "tenant": TenantIdentifier.from_dict(obj["tenant"]) if obj.get("tenant") is not None else None,
            "reference": obj.get("reference"),
            "userReference": obj.get("userReference"),
            "pipeline": PipelineV4.from_dict(obj["pipeline"]) if obj.get("pipeline") is not None else None,
            "workflowSession": WorkflowSessionV4.from_dict(obj["workflowSession"]) if obj.get("workflowSession") is not None else None,
            "status": obj.get("status"),
            "startDate": obj.get("startDate"),
            "endDate": obj.get("endDate"),
            "summary": obj.get("summary"),
            "analysisStorage": AnalysisStorageV4.from_dict(obj["analysisStorage"]) if obj.get("analysisStorage") is not None else None,
            "analysisPriority": obj.get("analysisPriority"),
            "tags": AnalysisTag.from_dict(obj["tags"]) if obj.get("tags") is not None else None,
            "application": ApplicationV4.from_dict(obj["application"]) if obj.get("application") is not None else None
        })
        return _obj


